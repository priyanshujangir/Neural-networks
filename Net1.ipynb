{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3878b55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1b99d3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import gzip\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "\n",
    "def cost_grad(a , y):\n",
    "    return (a-y)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0/(1.0 + np.exp(-z))\n",
    "\n",
    "def sig_diff(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))\n",
    "\n",
    "\n",
    "class Network():\n",
    "    def __init__(self , sizes):\n",
    "        self.sizes = sizes\n",
    "        self.num_layers = len(sizes)\n",
    "        self.biases = [np.random.randn(y , 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y,x) for y,x in zip(sizes[1:] , sizes[:-1])]\n",
    "        \n",
    "    def feedforward(self , a):\n",
    "        for b,w in zip(self.biases, self.weights):\n",
    "            a = np.matmul(w , a) + b\n",
    "        return a\n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta, lmbda = 5.0,evaluation_data=None):\n",
    "        if evaluation_data: n_data = len(evaluation_data)\n",
    "        n = len(training_data)\n",
    "        for j in range(epochs):\n",
    "            random.shuffle(training_data)\n",
    "            mini_batches = [training_data[k:mini_batch_size + k] for k in range(0, n , mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update(mini_batch , lmbda , eta , n)  \n",
    "            print(\"Epoch {} completed!!!\".format(j))\n",
    "      \n",
    "        accuracy = self.accuracy(training_data)\n",
    "        return accuracy\n",
    "    \n",
    "    def update(self ,mini_batch, lmbda ,eta, n ):\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        for x,y in mini_batch:\n",
    "            delta_nabla_b, delta_nabla_w = self.backprop(x,y)\n",
    "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "\n",
    "        self.weights = [(1-eta*lmbda/n)*w - (eta/len(mini_batch))*nw for w,nw in zip(self.weights, delta_nabla_w)]\n",
    "        self.biases = [b - (eta/len(mini_batch))*nb for b,nb in zip(self.biases,delta_nabla_b)]\n",
    "\n",
    "    def accuracy(self, data):\n",
    "        results = [(np.argmax(self.feedforward(x)), y) for (x, y) in data]\n",
    "        return sum(int(x == y) for (x, y) in results)\n",
    "\n",
    "        \n",
    "    def backprop(self, x , y ):\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        zs = []\n",
    "        x = np.reshape(x , (784,1))\n",
    "        acti = x\n",
    "        #print(\"acti:\",acti.shape)\n",
    "        \n",
    "        activations = [x]\n",
    "        for b,w in zip(self.biases , self.weights):\n",
    "            #print(\"w: \" , w.shape)\n",
    "            #print(\"x: \" , x.shape)\n",
    "            #print(\"1: \",np.matmul(w,acti).shape)\n",
    "            #print(\"b: \",b.shape)\n",
    "            z = np.add(np.matmul(w,acti) , b)\n",
    "            #print(\"z:\",z.shape)\n",
    "            zs.append(z)\n",
    "            acti = sigmoid(z)\n",
    "            activations.append(acti)\n",
    "            \n",
    "        delta = np.multiply(cost_grad(zs[-1] , y)  , sig_diff(zs[-1]))\n",
    "        #print(cost_grad(zs[-1] , y).shape)\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        for i in range(2 , self.num_layers):\n",
    "#             delta = np.multiply(np.matmul(nabla_w[-i+1].transpose() , delta) , sig_diff(zs[-i]))\n",
    "#             nabla_b = delta\n",
    "#             nabla_w = np.dot(delta , activations[-i-1].transpose())\n",
    "            delta = np.multiply(np.matmul(self.weights[-i+1].transpose(), delta) , sig_diff(zs[-i]))\n",
    "            #print(delta.shape)\n",
    "            nabla_b[-i] = delta\n",
    "            nabla_w[-i] = np.dot(delta, activations[-i-1].transpose())\n",
    "        return (nabla_b , nabla_w)\n",
    "\n",
    "    def default_weight_initializer(self):\n",
    "        self.biases = [np.random.randn(y, 1) for y in self.sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x)/np.sqrt(x) for x, y in zip(self.sizes[:-1], self.sizes[1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2a1daf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed!!!\n",
      "Epoch 1 completed!!!\n",
      "Epoch 2 completed!!!\n",
      "Epoch 3 completed!!!\n",
      "Epoch 4 completed!!!\n",
      "Epoch 5 completed!!!\n",
      "Epoch 6 completed!!!\n",
      "Epoch 7 completed!!!\n",
      "Epoch 8 completed!!!\n",
      "Epoch 9 completed!!!\n",
      "Epoch 10 completed!!!\n",
      "Epoch 11 completed!!!\n",
      "Epoch 12 completed!!!\n",
      "Epoch 13 completed!!!\n",
      "Epoch 14 completed!!!\n",
      "Epoch 15 completed!!!\n",
      "Epoch 16 completed!!!\n",
      "Epoch 17 completed!!!\n",
      "Epoch 18 completed!!!\n",
      "Epoch 19 completed!!!\n",
      "Epoch 20 completed!!!\n",
      "Epoch 21 completed!!!\n",
      "Epoch 22 completed!!!\n",
      "Epoch 23 completed!!!\n",
      "Epoch 24 completed!!!\n",
      "Epoch 25 completed!!!\n",
      "Epoch 26 completed!!!\n",
      "Epoch 27 completed!!!\n",
      "Epoch 28 completed!!!\n",
      "Epoch 29 completed!!!\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "mnist = loadmat(\"D:/Acads(sem-wise)/Some ML/data/mnist-original\")\n",
    "x = mnist[\"data\"].T\n",
    "y = mnist[\"label\"][0]\n",
    "random.shuffle(x)\n",
    "random.shuffle(y)\n",
    "x_train, x_test = x[:400], x[400:500]\n",
    "y_train, y_test = y[:400], y[400:500]\n",
    "\n",
    "\n",
    "training_data = [[x/255,y] for x,y in zip(x_train,y_train)]\n",
    "test_data = [ [x,y] for x,y in zip(x_test,y_test)]\n",
    "#print(training_data[0])\n",
    "net = Network([784, 30, 10])\n",
    "net.default_weight_initializer()\n",
    "print(net.SGD(training_data, 30, 10, 0.1, lmbda = 5.0,evaluation_data=test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c001cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
